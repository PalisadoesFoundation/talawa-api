##############################################################################
##############################################################################
#
# NOTE!
#
# Please read the README.md file in this directory that defines what should
# be placed in this file.
#
##############################################################################
##############################################################################

name: Pull request workflow
on:
  pull_request:
    branches:
      - "**"
env:
  CODECOV_UNIQUE_NAME: CODECOV_UNIQUE_NAME-${{ github.run_id }}-${{ github.run_number }}

jobs:
  check_base_branch:
    # only run the job if the pull request actor is not dependabot
    if: ${{ github.actor != 'dependabot[bot]' }}
    name: Check base branch of the pull request to be develop
    runs-on: ubuntu-latest
    steps:
      - if: github.event.pull_request.base.ref != 'develop'
        name: Check base branch
        run: |
          echo "Pull requests are only allowed against the 'develop' branch. Please refer to the pull request guidelines."
          echo "Error: Close this PR and try again."
          exit 1

  Code-Quality-Checks:
    name: Checking code quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout this repository
        uses: actions/checkout@v4.2.2
        with:
          fetch-depth: 0 # Fetch all history for git diff
      - name: Get changed files for error handling validation
        id: changed-files
        run: |
          # Skip if not in PR context
          if [ -z "${{ github.event.pull_request.base.sha }}" ]; then
            echo "changed_files=" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Get the base branch ref
          BASE_SHA=$(git merge-base ${{ github.event.pull_request.base.sha }} ${{ github.event.pull_request.head.sha }})

          # Get all changed files
          CHANGED_FILES=$(git diff --name-only --diff-filter=ACMRT $BASE_SHA ${{ github.event.pull_request.head.sha }} | tr '\n' ' ')
          echo "changed_files=${CHANGED_FILES}" >> $GITHUB_OUTPUT
      - name: Build talawa api non production environment docker image
        run: docker buildx build --file ./docker/api.Containerfile --tag talawa_api --target non_production ./
      - name: Check code format
        run: docker container run talawa_api pnpm format:check
      - name: Check TSDoc comments
        run: docker container run talawa_api pnpm lint:tsdoc
      - name: Check sanitization
        run: docker container run talawa_api pnpm lint:sanitization
      - name: Validate error handling standards
        env:
          CHANGED_FILES: ${{ steps.changed-files.outputs.changed_files }}
        run: docker container run -e CHANGED_FILES="$CHANGED_FILES" talawa_api pnpm validate:error-handling
      - name: Check if the source and target branches are different
        if: ${{ github.event.pull_request.base.ref == github.event.pull_request.head.ref }}
        run: |
          echo "Source Branch ${{ github.event.pull_request.head.ref }}"
          echo "Target Branch ${{ github.event.pull_request.base.ref }}"
          echo "Error: Source and Target Branches are the same. Please ensure they are different."
          echo "Error: Close this PR and try again."
          exit 1
      - name: Lint shell scripts (shellcheck)
        shell: bash
        run: |
          shopt -s globstar nullglob
          files=(scripts/**/*.sh tests/install/**/*.sh)
          if [ ${#files[@]} -eq 0 ]; then
            echo "No shell scripts found to lint."
          else
            shellcheck -x --severity=error "${files[@]}"
          fi

  Install-Script-Tests:
    name: Run install script tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout this repository
        uses: actions/checkout@v4.2.2
      # Use distro package (apt) for verifiable source; no tarball download or checksum needed
      - name: Install kcov
        run: |
          sudo add-apt-repository -y universe
          sudo apt-get update -qq
          sudo apt-get install -y kcov
          kcov --version
      - name: Run install script tests with coverage
        run: |
          mkdir -p ./coverage/install
          kcov --include-path=scripts/install --exclude-path=tests ./coverage/install bash tests/install/run-all.sh
      - name: Upload install coverage to Codecov
        if: success() && hashFiles('coverage/install/**/cobertura.xml') != ''
        uses: codecov/codecov-action@v5
        with:
          name: "${{env.CODECOV_UNIQUE_NAME}}-install"
          token: ${{ secrets.CODECOV_TOKEN }}
          fail_ci_if_error: false
          verbose: true
          directory: ./coverage/install
          flags: install

  Python-Compliance:
    name: Check Python Code Style
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      - name: Cache pip packages
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python3 -m venv venv
          source venv/bin/activate
          python -m pip install --upgrade pip
          pip install -r .github/workflows/requirements.txt

      - name: Run Black Formatter Check
        run: |
          source venv/bin/activate
          black --check .

      - name: Run Flake8 Linter
        run: |
          source venv/bin/activate
          flake8 --docstring-convention google --ignore E402,E722,E203,F401,W503 .github

      - name: Run pydocstyle
        run: |
          source venv/bin/activate
          pydocstyle --convention=google --add-ignore=D415,D205 .github

      - name: Run docstring compliance check
        run: |
          source venv/bin/activate
          python .github/workflows/scripts/check_docstrings.py --directories .github

  Count-Changed-Files:
    uses: PalisadoesFoundation/.github/.github/workflows/count-changed-files.yml@main

  python_checks:
    name: Run Python Checks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Checkout centralized scripts
        uses: actions/checkout@v4
        with:
          repository: PalisadoesFoundation/.github
          path: .github-central
          ref: main

      - name: Get changed files
        id: changed-files
        run: |
          ALL_CHANGED_FILES=$(git diff --name-only --diff-filter=ACMRT ${{ github.event.pull_request.base.sha }} ${{ github.event.pull_request.head.sha }})
          # Skip binary assets that cannot be decoded as UTF-8 by the disable-statements check
          FILTERED_FILES=$(echo "$ALL_CHANGED_FILES" | grep -Ev '\.(png|jpg|jpeg|gif|webp)$' || true)
          echo "all_changed_files=$(echo "$FILTERED_FILES" | tr '\n' ' ')" >> $GITHUB_OUTPUT

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.9

      - name: Run Disable Statements Check
        run: |
          if [ -z "${{ steps.changed-files.outputs.all_changed_files }}" ]; then
            echo "No eligible text files changed; skipping disable statements check."
            exit 0
          fi
          python .github-central/.github/workflows/scripts/disable_statements_check.py --files ${{ steps.changed-files.outputs.all_changed_files }}

  check_gql_tada:
    name: Check gql tada files and configuration
    runs-on: ubuntu-latest
    steps:
      - name: Checkout this repository
        uses: actions/checkout@v4.2.2
      - name: Build talawa api non production environment docker image
        run: docker buildx build --file ./docker/api.Containerfile --tag talawa_api --target non_production ./
      - name: Check gql tada
        run: docker container run talawa_api pnpm check_gql_tada

  check_drizzle_migrations:
    name: Check drizzle migration files
    runs-on: ubuntu-latest
    steps:
      - name: Checkout this repository
        uses: actions/checkout@v4.2.2
      - name: Build talawa api non production environment docker image
        run: docker buildx build --file ./docker/api.Containerfile --tag talawa_api --target non_production ./
      - name: Check drizzle migrations
        run: docker container run --env-file ./envFiles/.env.ci talawa_api pnpm check_drizzle_migrations

  check_type_errors:
    name: Check type errors
    runs-on: ubuntu-latest
    steps:
      - name: Checkout this repository
        uses: actions/checkout@v4.2.2
      - name: Build talawa api non production environment docker image
        run: docker buildx build --file ./docker/api.Containerfile --tag talawa_api --target non_production ./
      - name: Check type errors
        run: docker container run talawa_api pnpm typecheck

  check_mock_isolation:
    name: Check mock isolation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout this repository
        uses: actions/checkout@v4.2.2
      - name: Build talawa api non production environment docker image
        run: docker buildx build --file ./docker/api.Containerfile --tag talawa_api --target non_production ./
      - name: Check mock isolation
        run: docker container run talawa_api pnpm check_mock_isolation

  Check_unused_code:
    name: Check for unused files, exports and dependencies
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4.2.2
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "24.x"
      - name: Setup pnpm
        uses: pnpm/action-setup@v4
      - name: Install dependencies
        run: pnpm install --frozen-lockfile
      - name: Run Knip for files and exports
        run: pnpm knip --include files,exports
        # Dummy environment variables required for Knip to load drizzle.config.ts during file parsing
        env:
          API_POSTGRES_DATABASE: dummy_db
          API_POSTGRES_PASSWORD: dummy_password
          API_POSTGRES_HOST: localhost
          API_POSTGRES_PORT: "5432"
          API_POSTGRES_USER: dummy_user
          API_POSTGRES_SSL_MODE: "false"
      - name: Run Knip for dependencies
        run: pnpm knip --config knip.deps.json --include dependencies
        # Dummy environment variables required for Knip to load drizzle.config.ts during file parsing
        env:
          API_POSTGRES_DATABASE: dummy_db
          API_POSTGRES_PASSWORD: dummy_password
          API_POSTGRES_HOST: localhost
          API_POSTGRES_PORT: "5432"
          API_POSTGRES_USER: dummy_user
          API_POSTGRES_SSL_MODE: "false"

  Check-Sensitive-Files:
    if: ${{ github.actor != 'dependabot[bot]' }}
    name: Checks if sensitive files have been changed without authorization
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetch all history for all branches and tags

      - name: Get PR labels
        id: check-labels
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          if [ -z "${{ github.event.pull_request.number }}" ]; then
            echo "skip=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          LABELS="$(gh api repos/${{ github.repository }}/issues/${{ github.event.pull_request.number }}/labels --jq '.[].name' | tr '\n' ' ')"

          if echo "$LABELS" | grep -qw "ignore-sensitive-files-pr"; then
            echo "::notice::Skipping sensitive files check due to 'ignore-sensitive-files-pr' label."
            echo "skip=true" >> $GITHUB_OUTPUT
          else
            echo "skip=false" >> $GITHUB_OUTPUT
          fi

      - name: Get Changed Unauthorized files
        if: steps.check-labels.outputs.skip != 'true'
        id: changed-unauth-files
        run: |
          set -e

          # Skip if not in PR context
          if [ -z "${{ github.event.pull_request.base.sha }}" ]; then
            echo "any_changed=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Determine base and head commits for comparison
          HEAD_SHA="${{ github.event.pull_request.head.sha || github.sha }}"
          BASE_SHA=$(git merge-base "${{ github.event.pull_request.base.sha }}" "$HEAD_SHA" 2>&1) || {
            echo "::error::Failed to find merge base between ${{ github.event.pull_request.base.sha }} and $HEAD_SHA" >&2
            exit 1
          }

          # Verify BASE_SHA is not empty
          if [ -z "$BASE_SHA" ]; then
            echo "::error::BASE_SHA is empty after git merge-base command" >&2
            exit 1
          fi

          # Define sensitive files patterns as a bash array
          SENSITIVE_PATTERNS=(
            '.coderabbit.yaml$'
            '^.coderabbit/.*'            
            'Caddyfile$'
            'codegen.ts$'
            '^Dockerfile.*'
            '^docker/.*'
            '^docker-compose.*'
            '^drizzle_migrations/.*'
            '^scripts/.*'
            '.dockerignore$'
            '.env.sample$'
            '.env_test$'
            'eslint.config.mjs$'
            '^envFiles/.*'
            '.gitignore$'
            'init-mongo.sh$'
            '.prettierignore$'
            '.prettierrc.json$'
            '.pylintrc$'
            '^.github/.*'            
            'biome.jsonc$'
            'renovate.json$'
            'requirements.txt$'
            'schema.graphql$'
            'CODEOWNERS$'
            'LICENSE$'
            'tsconfig.json$'
            'vitest.config.ts$'
            'vitest.*.config.ts$'
            'codecov.yml$'
            'pnpm-lock.yaml$'
            'package.json$'
            'package-lock.json$'
            '.nojekyll$'
            'knip.json$'
            'docs/docusaurus.config.ts$'
            '^docs/sidebar.*'
            'setup.ts$'
            '^src/graphql/types/Mutation/.*'
            '^src/graphql/types/Query/.*'
            'tsconfig.build.json$'
            'vite.config.mts$'
            'CNAME$'
            'CODE_OF_CONDUCT.md$'
            'CODE_STYLE.md$'
            'CONTRIBUTING.md$'
            'DOCUMENTATION.md$'
            'INSTALLATION.md$'
            'ISSUE_GUIDELINES.md$'
            'PR_GUIDELINES.md$'
            'README.md$'
            '^./*md'
            '^./*txt'
            '^./*TXT'
          )

          # Check for changes in sensitive files
          CHANGED_UNAUTH_FILES=""
          for pattern in "${SENSITIVE_PATTERNS[@]}"; do
            FILES=$(git diff --name-only --diff-filter=ACMRD "$BASE_SHA" "$HEAD_SHA" | grep -E "$pattern" || true)
            if [ ! -z "$FILES" ]; then
              CHANGED_UNAUTH_FILES="$CHANGED_UNAUTH_FILES $FILES"
            fi
          done

          # Deduplicate and format output
          # Convert to newline-separated, deduplicate, then rejoin as space-separated
          if [ ! -z "$CHANGED_UNAUTH_FILES" ]; then
            CHANGED_UNAUTH_FILES=$(echo "$CHANGED_UNAUTH_FILES" | tr ' ' '\n' | sort -u | tr '\n' ' ' | xargs)
          fi

          echo "all_changed_files=$CHANGED_UNAUTH_FILES" >> $GITHUB_OUTPUT

          # Check if any unauthorized files changed
          if [ ! -z "$CHANGED_UNAUTH_FILES" ]; then
            echo "any_changed=true" >> $GITHUB_OUTPUT
          else
            echo "any_changed=false" >> $GITHUB_OUTPUT
          fi

      - name: List all changed unauthorized files
        if: steps.changed-unauth-files.outputs.any_changed == 'true'
        env:
          CHANGED_UNAUTH_FILES: ${{ steps.changed-unauth-files.outputs.all_changed_files }}
        run: |
          echo "::error::Unauthorized changes detected in sensitive files:"
          echo ""
          for file in $CHANGED_UNAUTH_FILES; do
            echo "- $file"
          done
          echo ""
          echo "To override:"
          echo "Add the 'ignore-sensitive-files-pr' label to this PR."
          exit 1

  Check-AutoDocs:
    needs: [Code-Quality-Checks]
    uses: PalisadoesFoundation/.github/.github/workflows/typescript-autodocs.yml@main
    with:
      pnpm-version: "10.26.1"
  Generate-Schema-Docs:
    if: ${{ github.actor != 'dependabot[bot]' }}
    name: Generate GraphQL Schema Documentation
    runs-on: ubuntu-latest
    needs: [Code-Quality-Checks]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          run_install: false

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "24.x"
          cache: "pnpm"

      - name: Prepare dependency store
        run: pnpm fetch

      - name: Install Docs dependencies
        working-directory: ./docs
        run: pnpm install --frozen-lockfile --prefer-offline

      - name: Generate GraphQL Schema Markdown
        working-directory: ./docs
        run: pnpm docusaurus graphql-to-doc
      - name: Check for uncommitted schema changes
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "::error::Schema files are outdated or missing."
            echo "Please run 'pnpm docusaurus graphql-to-doc' inside '/docs' locally and commit the updated files."
            echo ""
            echo "Changed files:"
            git status --porcelain
            exit 1
          else
            echo "Schema is up to date."
          fi

  Pre-Test-Checks-Pass:
    name: All Pre-Testing Checks Pass
    runs-on: ubuntu-latest
    needs:
      [
        Code-Quality-Checks,
        python_checks,
        check_type_errors,
        check_mock_isolation,
        check_drizzle_migrations,
        check_gql_tada,
        Check-AutoDocs,
        Check_unused_code,
        Generate-Schema-Docs,
        Python-Compliance,
      ]
    steps:
      - name: This job intentionally does nothing
        run: echo "This job intentionally does nothing"

  Run-Tests:
    name: Run tests for talawa api (Shard ${{ matrix.shard }})
    timeout-minutes: 10
    runs-on: ubuntu-latest
    needs: [Pre-Test-Checks-Pass]
    env:
      TOTAL_SHARDS: 12
    strategy:
      fail-fast: false
      matrix:
        shard: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
    steps:
      - name: Checkout this repository
        uses: actions/checkout@v4.2.2
      - name: Create .env file for talawa api testing environment
        run: cp ./envFiles/.env.ci ./.env
      - name: Build talawa api compose testing environment
        run: docker compose build
      - name: Start test services (postgres-test, minio-test, redis-test, mailpit)
        run: docker compose up -d postgres-test minio-test redis-test mailpit
      - name: Wait for test services to be ready
        run: |
          set -euo pipefail
          echo "Waiting for Postgres test service..."
          timeout=90
          until docker compose exec -T postgres-test pg_isready -h localhost -p 5432 -U postgres >/dev/null 2>&1 || [ $timeout -eq 0 ]; do
            echo "Postgres not ready yet... ($timeout seconds remaining)"
            sleep 1
            ((timeout--))
          done
          if [ $timeout -eq 0 ]; then
            echo "Error: Postgres failed to start"
            docker compose ps
            docker compose logs postgres-test
            docker compose down -v
            exit 1
          fi
          echo "Postgres is ready."

          # Wait for minio-test health check
          echo "Waiting for Minio test service..."
          timeout=60
          until docker compose exec -T minio-test mc ready local >/dev/null 2>&1 || [ $timeout -eq 0 ]; do
            echo "Minio not ready yet... ($timeout seconds remaining)"
            sleep 1
            ((timeout--))
          done
          if [ $timeout -eq 0 ]; then
            echo "::warning::Minio health check timed out, continuing anyway"
          else
            echo "Minio is ready."
          fi

          # Wait for redis-test health check
          echo "Waiting for Redis test service..."
          timeout=60
          until docker compose exec -T redis-test redis-cli ping >/dev/null 2>&1 || [ $timeout -eq 0 ]; do
            echo "Redis not ready yet... ($timeout seconds remaining)"
            sleep 1
            ((timeout--))
          done
          if [ $timeout -eq 0 ]; then
            echo "::warning::Redis health check timed out, continuing anyway"
          else
            echo "Redis is ready."
          fi

          # Wait for mailpit health check
          echo "Waiting for Mailpit service..."
          timeout=60
          until curl -f http://localhost:8025/api/v1/info >/dev/null 2>&1 || [ $timeout -eq 0 ]; do
            echo "Mailpit not ready yet... ($timeout seconds remaining)"
            sleep 1
            ((timeout--))
          done
          if [ $timeout -eq 0 ]; then
            echo "::warning::Mailpit health check timed out, continuing anyway"
          else
            echo "Mailpit is ready."
          fi

          echo "All test services are ready."

      - name: Test Mailpit email service
        run: |
          echo "Testing Mailpit email service..."
          
          # Test Mailpit API is responding
          MAILPIT_INFO=$(curl -s http://localhost:8025/api/v1/info 2>/dev/null || echo '{}')
          echo "Mailpit info: $MAILPIT_INFO"
          
          # Check if Mailpit API is responding with valid data
          if echo "$MAILPIT_INFO" | grep -q '"version"'; then
            echo "SUCCESS: Mailpit API is responding correctly"
            echo "SUCCESS: Mailpit is ready to capture emails"
          else
            echo "::warning::Mailpit API may not be responding properly"
          fi
          
          # Note: Email functionality will be tested during the actual test suite execution
          # The API container will use Mailpit as configured in .env.ci
      - name: Run tests (shard ${{ matrix.shard }}/${{ env.TOTAL_SHARDS }})
        env:
          SHARD_INDEX: ${{ matrix.shard }}
          SHARD_COUNT: ${{ env.TOTAL_SHARDS }}
        run: |
          # Run tests without --rm to allow coverage extraction
          docker compose run --name talawa-api-test-shard-${{ matrix.shard }} \
            -e SHARD_INDEX=$SHARD_INDEX \
            -e SHARD_COUNT=$SHARD_COUNT \
            api /bin/sh -c "node scripts/run-shard.js --coverage -c vitest.unit.config.ts --coverage.reportsDirectory=./coverage/unit && node scripts/run-shard.js --coverage -c vitest.integration.config.ts --coverage.reportsDirectory=./coverage/integration"

      - name: Copy coverage from container
        if: always()
        run: |
          # Copy coverage from the named container
          docker cp talawa-api-test-shard-${{ matrix.shard }}:/home/talawa/api/coverage ./coverage || echo "::warning::Failed to copy coverage from container talawa-api-test-shard-${{ matrix.shard }}"

      - name: Cleanup test container
        if: always()
        run: |
          # Remove the test container
          docker rm -f talawa-api-test-shard-${{ matrix.shard }} || true
      - name: Upload coverage artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-shard-${{ matrix.shard }}
          path: ./coverage/
          retention-days: 1

  Merge-Coverage:
    name: Merge Coverage Reports
    runs-on: ubuntu-latest
    needs: [Run-Tests]
    if: success()
    steps:
      - name: Checkout the Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Fetch base branch for Codecov comparison
        run: |
          set -e
          echo "Fetching base branch: ${{ github.base_ref }}"
          if ! git fetch origin ${{ github.base_ref }} 2>&1; then
            echo "ERROR: Failed to fetch base branch '${{ github.base_ref }}' from origin"
            exit 1
          fi
          echo "Successfully fetched base branch"

      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          run_install: false

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "24.x"
          cache: "pnpm"

      - name: Prepare dependency store
        run: pnpm fetch

      - name: Install Dependencies
        run: pnpm install --frozen-lockfile --prefer-offline

      - name: Download all coverage artifacts
        id: download-artifacts
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          pattern: coverage-shard-*
          path: ./coverage-shards/
          merge-multiple: false

      - name: Check if artifacts were downloaded
        id: check-artifacts
        run: |
          # Check if any coverage files exist
          if find coverage-shards -name "lcov.info" -type f | grep -q .; then
            echo "artifacts_found=true" >> $GITHUB_OUTPUT
            echo "Coverage artifacts found"
          else
            echo "artifacts_found=false" >> $GITHUB_OUTPUT
            echo "No coverage artifacts found - tests may have been skipped"
          fi

      - name: Prepare Split Coverage Reports
        if: steps.check-artifacts.outputs.artifacts_found == 'true'
        run: |
          # Function to merge and generate report for a specific type (unit or integration)
          process_coverage() {
            TYPE=$1
            echo "Processing $TYPE coverage..."

            mkdir -p ./coverage/$TYPE
            mkdir -p .nyc_output_$TYPE

            # Find all coverage-final.json files for this type
            # Expected path: coverage-shards/coverage-shard-*/$TYPE/coverage-final.json
            find coverage-shards -path "*/$TYPE/coverage-final.json" -type f > json-files-$TYPE.txt

            JSON_COUNT=$(wc -l < json-files-$TYPE.txt)
            echo "Found $JSON_COUNT JSON files for $TYPE"

            if [ "$JSON_COUNT" -eq 0 ]; then
              echo "::warning::No coverage files found for $TYPE"
              return
            fi

            # Copy to unique names
            SHARD_NUM=0
            while IFS= read -r file; do
              cp "$file" ".nyc_output_$TYPE/coverage-shard-${SHARD_NUM}.json"
              SHARD_NUM=$((SHARD_NUM + 1))
            done < json-files-$TYPE.txt

            # Merge
            pnpm exec nyc merge .nyc_output_$TYPE ./coverage/$TYPE/coverage-final.json

            # Path rewrite
            DOCKER_PATH="/home/talawa/api"
            RUNNER_PATH="$GITHUB_WORKSPACE"
            sed -i "s|${DOCKER_PATH}|${RUNNER_PATH}|g" ./coverage/$TYPE/coverage-final.json

            # Report
            rm -rf .nyc_output
            mkdir -p .nyc_output
            cp ./coverage/$TYPE/coverage-final.json .nyc_output/coverage-final.json
            
            pnpm exec nyc report --reporter=lcov --report-dir=./coverage/$TYPE

            rm -rf .nyc_output_$TYPE
          }

          process_coverage "unit"
          process_coverage "integration"

          # Create a combined report for local VeryGoodCoverage check
          echo "Merging ALL coverage for local check..."
          mkdir -p .nyc_output_all
          mkdir -p ./coverage/vitest

          find coverage-shards -name "coverage-final.json" -type f > json-files-all.txt

          SHARD_NUM=0
          while IFS= read -r file; do
             cp "$file" ".nyc_output_all/coverage-shard-${SHARD_NUM}.json"
             SHARD_NUM=$((SHARD_NUM + 1))
          done < json-files-all.txt

          pnpm exec nyc merge .nyc_output_all ./coverage/vitest/coverage-final.json

          # Path rewrite
          DOCKER_PATH="/home/talawa/api"
          RUNNER_PATH="$GITHUB_WORKSPACE"
          sed -i "s|${DOCKER_PATH}|${RUNNER_PATH}|g" ./coverage/vitest/coverage-final.json

          # Report
          rm -rf .nyc_output
          mkdir -p .nyc_output
          cp ./coverage/vitest/coverage-final.json .nyc_output/coverage-final.json
          pnpm exec nyc report --reporter=lcov --report-dir=./coverage/vitest

          rm -rf .nyc_output_all .nyc_output

      - name: Calculate merge base for Codecov
        if: steps.check-artifacts.outputs.artifacts_found == 'true'
        id: get-merge-base
        run: |
          MERGE_BASE=$(git merge-base origin/${{ github.base_ref }} HEAD)
          echo "Merge base commit: $MERGE_BASE"
          echo "merge_base=$MERGE_BASE" >> $GITHUB_OUTPUT

          git show -s --format=%ci $MERGE_BASE

      #######################################################################
      # DO NOT DELETE ANY references to env.CODECOV_UNIQUE_NAME in this
      # section. They are required for accurate calculations
      #######################################################################
      - name: Upload Unit Coverage to Codecov
        if: steps.check-artifacts.outputs.artifacts_found == 'true'
        uses: codecov/codecov-action@v5
        with:
          name: "${{env.CODECOV_UNIQUE_NAME}}-unit"
          token: ${{ secrets.CODECOV_TOKEN }}
          fail_ci_if_error: true
          verbose: true
          exclude: "docs/"
          gcov_ignore: "docs/"
          files: ./coverage/unit/lcov.info
          flags: unit

      - name: Upload Integration Coverage to Codecov
        if: steps.check-artifacts.outputs.artifacts_found == 'true'
        uses: codecov/codecov-action@v5
        with:
          name: "${{env.CODECOV_UNIQUE_NAME}}-integration"
          token: ${{ secrets.CODECOV_TOKEN }}
          fail_ci_if_error: true
          verbose: true
          exclude: "docs/"
          gcov_ignore: "docs/"
          files: ./coverage/integration/lcov.info
          flags: integration

      - name: Test acceptable level of code coverage
        if: steps.check-artifacts.outputs.artifacts_found == 'true'
        uses: VeryGoodOpenSource/very_good_coverage@v3
        with:
          path: "./coverage/vitest/lcov.info"
          min_coverage: 80.0

  Test-Docusaurus-Deployment:
    name: Test Deployment to https://docs-api.talawa.io
    runs-on: ubuntu-latest
    needs: [Run-Tests]
    # Run only if the develop branch and not dependabot
    if: ${{ github.actor != 'dependabot[bot]' && github.event.pull_request.base.ref == 'develop' }}
    steps:
      - uses: actions/checkout@v4
      - uses: pnpm/action-setup@v4
        with:
          cache: pnpm
          cache-dependency-path: |
            docs/pnpm-lock.yaml
            docs/package.json
      # Run Docusaurus in the ./docs directory
      - name: Install dependencies
        working-directory: ./docs
        run: pnpm install --frozen-lockfile
      - name: Test building the website
        working-directory: ./docs
        run: pnpm build

  Check-Sample-Data:
    name: Check If Sample Data Script Executes Successfully
    timeout-minutes: 5
    runs-on: ubuntu-latest
    needs: [Run-Tests]
    steps:
      - name: Checkout Backend
        uses: actions/checkout@v4.2.2

      - name: Setup Devcontainer
        run: |
          npm install -g @devcontainers/cli
          cp envFiles/.env.devcontainer .env
          devcontainer up --workspace-folder . --config .devcontainer/default/devcontainer.json
          echo "Devcontainer started"
      - name: Wait for Postgres in devcontainer before migrations
        run: |
          set -euo pipefail
          POSTGRES_USER=postgres
          echo "Waiting for Postgres service via compose..."
          timeout=90
          until docker compose exec -T postgres pg_isready -h localhost -p 5432 -U "$POSTGRES_USER" >/dev/null 2>&1 || [ "$timeout" -le 0 ]; do
            echo "Postgres not ready ($timeout s left)"
            sleep 1
            ((timeout--))
          done
          if [ "$timeout" -eq 0 ]; then
            echo "Error: Postgres failed to start"
            docker compose ps
            docker compose logs postgres
            exit 1
          fi

      - name: Apply Database Migrations
        run: |
          docker exec talawa-api-1 /bin/bash -c 'pnpm apply_drizzle_migrations'

      - name: Start Backend Server
        run: |
          docker exec -d talawa-api-1 /bin/bash -c 'pnpm run start_development_server'

      - name: Wait for Backend to be Ready
        run: |
          echo "Waiting for backend at http://localhost:4000/healthcheck"

          TIMEOUT=60
          INTERVAL=3
          ELAPSED=0

          until docker exec talawa-api-1 curl -sf http://localhost:4000/healthcheck > /dev/null; do
            if [ "$ELAPSED" -ge "$TIMEOUT" ]; then
              echo "Backend failed to start within ${TIMEOUT}s"
              echo "=== Backend container logs ==="
              docker logs talawa-api-1 --tail 100
              exit 1
            fi
            echo "Backend not ready yet... (${ELAPSED}s)"
            sleep $INTERVAL
            ELAPSED=$((ELAPSED + INTERVAL))
          done

          echo "Backend is up and responding"

      - name: Seed Sample Data
        run: |
          set -euo pipefail
          echo "=== Seeding Sample Data ==="
          if docker exec talawa-api-1 /bin/bash -c 'set -a; source ./.env; set +a; pnpm run add:sample_data'; then
            echo "Seeding completed successfully"
          else
            echo "Seeding failed"
            echo "=== Container status ==="
            docker ps | grep talawa || true
            echo "=== Backend logs ==="
            docker logs talawa-api-1 --tail 50
            echo "=== Users table contents ==="
            docker exec talawa-postgres-1 psql -U talawa -d talawa \
              -c "SELECT id, email_address, name, role FROM users;" \
              2>/dev/null || echo "Could not query users"
            exit 1
          fi

      - name: Cleanup - Free ports by stopping containers
        if: always()
        run: |
          docker compose down

  Check-App-Startup:
    name: Check App Startup and Health
    runs-on: ubuntu-latest
    needs: [Run-Tests]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4.2.2
      - name: Install Devcontainer CLI
        run: npm install -g @devcontainers/cli
      - name: Copy devcontainer environment file
        run: cp envFiles/.env.devcontainer .env
      - name: Bring up devcontainer
        run: devcontainer up --workspace-folder . --config .devcontainer/default/devcontainer.json
      - name: Wait for Postgres in devcontainer
        run: |
          set -euo pipefail
          POSTGRES_USER=postgres
          echo "Waiting for Postgres service via compose..."
          timeout=90
          until docker compose exec -T postgres pg_isready -h localhost -p 5432 -U "$POSTGRES_USER" >/dev/null 2>&1 || [ "$timeout" -le 0 ]; do
            echo "Postgres not ready ($timeout s left)"
            sleep 1
            ((timeout--))
          done
          if [ "$timeout" -eq 0 ]; then
            echo "Error: Postgres failed to start"
            docker compose ps
            docker logs postgres
            exit 1
          fi
      - name: Wait for Devcontainer to be ready
        run: |
          echo "Waiting for devcontainer services to be ready..."
          sleep 10
      - name: Verify Running Containers
        run: docker ps
      - name: Install dependencies inside the container
        run: docker exec talawa-api-1 /bin/bash -c 'pnpm install'
      - name: Start server and monitor logs
        run: |
          docker exec talawa-api-1 /bin/bash -c 'pnpm run start_development_server' &
          sleep 10
      - name: Wait for GraphQL endpoint to become available
        if: always()
        run: |
          echo "Waiting for the GraphQL endpoint to become available..."
          for i in {1..60}; do
            # Check if container exists first
            if ! docker ps | grep -q talawa-api-1; then
              echo "Container talawa-api-1 not found. Waiting..."
              sleep 2
              continue
            fi
            docker exec talawa-api-1 which curl >/dev/null 2>&1 || {
              docker exec talawa-api-1 apt-get update && docker exec talawa-api-1 apt-get install -y curl
            }
            RESPONSE=$(docker exec talawa-api-1 curl -s -X POST http://127.0.0.1:4000/graphql -H "Content-Type: application/json" -d '{"query":"{__typename}"}' 2>/dev/null || echo "Connection failed")
            if echo "$RESPONSE" | grep -q '__typename'; then
              echo "GraphQL endpoint is available!"
              exit 0
            fi
            echo "GraphQL endpoint not ready. Retrying in 2 seconds..."
            sleep 2
          done
          echo "GraphQL endpoint did not become available within the expected time."
          exit 1
      - name: Cleanup - Free ports by stopping containers
        if: always()
        run: docker compose down
